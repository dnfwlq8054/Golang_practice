# 9장 공유 변수를 이용한 동시성

## 9.5 늦은 초기화 : sync.Once
비용이 많은 드는 초기화 같은 경우에는 꼭 필요할 때 까지 초기화를 늦추는 편이 좋습니다. 
변수를 처음부터 초기화 하는 것은 프로그램의 시작 시간을 늦추고, 프로그램 실행 시 항상 해당 변수를 사용하는 부분에 도달하지 않는다면 불필요한 작업이 됩니다.

```go
var icons map[string]image.Image
func loadIcon {
    var icons = map[string]image.Image {
    "spades.png":   loadIcon("spades.png")
    "hearts.png":   loadIcon("hearts.png")
    "diamonds.png": loadIcon("diamonds.png")
    "clubs.png":    loadIcon("clubs.png")
}
// Ex 1)
var mu sync.Mutex
func Icon(name string) image.Image {
    mu.Lock()
    defer mu.Unlock()
    if icons == nil {
        loadIcons()
    }
    return icons[name]
}

// Ex 2)
var mu sync.RWMutex
func Icon(name string) image.Image {
    mu.RLock()
    if icons != nil {
        icon := icons[name]
        mu.Runlock()
        return icon
    }
    mu.RUnlock()

    mu.Lock()
    if icons == nil {
        loadIcons()
    }
    icon := icons[name]
    mu.Unlock()
    return icon
}
```
icnos 에 대한 늦은 초기화 예제입니다. 첫 번째 예제는 안전하게 동기화를 맞춰주고 있지만, 여러 고루틴이 `Icon()` 함수에 접근하게 되면 꽤나 큰 리소스를 잡아먹게 됩니다.
두 번째 예제는 첫 번째 예제보다 리소르를 덜 먹게 되지만, 하나의 함수 안에서 `RLock()`과 `Lock()`이 동시에 이뤄지므로 오류가 발생하기 쉽습니다. (즉, 별로 좋지 않은 코드)

이를 한번에 개선시킬 함수가 `sync.Once` 패키지의 `Do()` 입니다.
```go
var loadIconsOnce sync.Once
var icons map[string]image.Image

func Icon(name string) image.Image {
    loadIconsOnce.Do(loadIcons)
    return icons[name]
}
```
해당 `Do()` 는 내부적으로 if문을 통해 해당 원자값(`done unit32`)을 확인하여 해당 값이 0이라면 `Lock()`을 한번 실행하고 원자값을 1로 변경해줍니다.
이렇게 함으로써 `Do()`에 포함된 함수는 1번만 실행이 가능해집니다.
```go
package sync

import (
	"sync/atomic"
)

// Once is an object that will perform exactly one action.
//
// A Once must not be copied after first use.
type Once struct {
	// done indicates whether the action has been performed.
	// It is first in the struct because it is used in the hot path.
	// The hot path is inlined at every call site.
	// Placing done first allows more compact instructions on some architectures (amd64/386),
	// and fewer instructions (to calculate offset) on other architectures.
	done uint32
	m    Mutex
}

// Do calls the function f if and only if Do is being called for the
// first time for this instance of Once. In other words, given
// 	var once Once
// if once.Do(f) is called multiple times, only the first call will invoke f,
// even if f has a different value in each invocation. A new instance of
// Once is required for each function to execute.
//
// Do is intended for initialization that must be run exactly once. Since f
// is niladic, it may be necessary to use a function literal to capture the
// arguments to a function to be invoked by Do:
// 	config.once.Do(func() { config.init(filename) })
//
// Because no call to Do returns until the one call to f returns, if f causes
// Do to be called, it will deadlock.
//
// If f panics, Do considers it to have returned; future calls of Do return
// without calling f.
//
func (o *Once) Do(f func()) {
	// Note: Here is an incorrect implementation of Do:
	//
	//	if atomic.CompareAndSwapUint32(&o.done, 0, 1) {
	//		f()
	//	}
	//
	// Do guarantees that when it returns, f has finished.
	// This implementation would not implement that guarantee:
	// given two simultaneous calls, the winner of the cas would
	// call f, and the second would return immediately, without
	// waiting for the first's call to f to complete.
	// This is why the slow path falls back to a mutex, and why
	// the atomic.StoreUint32 must be delayed until after f returns.

	if atomic.LoadUint32(&o.done) == 0 {
		// Outlined slow-path to allow inlining of the fast-path.
		o.doSlow(f)
	}
}

func (o *Once) doSlow(f func()) {
	o.m.Lock()
	defer o.m.Unlock()
	if o.done == 0 {
		defer atomic.StoreUint32(&o.done, 1)
		f()
	}
}
```
위 코드는 `sync.Once`의 `Do()` 함수 부분입니다. 여기서 `doSlow()` 함수에 있는 `atomic`패키지는 메모리에 특정 값을 저장한 후 
고 루틴들이 통신을 이용해 값을 받아가도록 만들어 졌다고 합니다.(메모리 공유가 아닙니다.)

##### sync.Once 예제.
https://go.dev/play/p/oSRlNKMcwNn

## 9.6 경쟁 상태 검출
아무리 꼼꼼하게 살펴보더라도 동시성에 관련된 실수를 하기 쉽습니다. 다행히도 Go 런타임과 도구에는 정교하고 사용하기 쉬운 동적 분석 도구인 경쟁 상태 검출기가 내장되어 있습니다.
`go build, go run, go test` 명령어 뒤에 `-race` 플래그만 추가하면 됩니다.
```go
// main.go
package main

import (
	"fmt"
	"log"
	"sync"
	"time"
)

const MAX = 1000

func main() {
	start := time.Now()
	var wg sync.WaitGroup
	var once sync.Once
	var count int

	for i := 0; i < MAX; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			once.Do(func() {
				fmt.Println("hi")
			})
			count += 1
		}()
	}
	wg.Wait()

	fmt.Printf("count = %d\n", count)
	defer log.Printf("[time] Elipsed Time: %s", time.Since(start))
}
```
```
$ go run -race test.go

// OutPut
hi
==================
WARNING: DATA RACE
Read at 0x00c0000c2030 by goroutine 8:
  main.main.func1()
      /home/kyounghwanchoi/Golang_practice/test.go:26 +0x8c

Previous write at 0x00c0000c2030 by goroutine 7:
  main.main.func1()
      /home/kyounghwanchoi/Golang_practice/test.go:26 +0xa5

Goroutine 8 (running) created at:
  main.main()
      /home/kyounghwanchoi/Golang_practice/test.go:21 +0x195

Goroutine 7 (finished) created at:
  main.main()
      /home/kyounghwanchoi/Golang_practice/test.go:21 +0x195
==================
count = 999
2022/02/13 18:26:12 [time] Elipsed Time: 103.957805ms
Found 1 data race(s)
exit status 66
```
위 예시는 경쟁상태가 발생했을 경우입니다. 해당 검출기는 go 구문, 채널 연산, Lock, Wait 등의 모든 동기화 이벤트를 기록합니다.
하지만 실행시 경쟁 상태만 감지할 수 있고, 경쟁 상태를 발생하지 않게 할 수는 없습니다.
따라서 최고의 결과를 얻어내려면 테스트 코드를 작성해 테스트를 진행해야 합니다.

## 9.7 동시 넌블로킹 캐시
기존 라이브러리로 처리하기 어렵지만 실제 동시성 프로그램에서 자주 발생하는 문제를 해결하는
추상화 계층인 동시 넌브로킹 캐시를 만드는 장입니다.

```go
//memo_test.go

package memo_test

import (
	"testing"

	"gopl.io/ch9/memo5"
	"gopl.io/ch9/memotest"
)

var httpGetBody = memotest.HTTPGetBody

func TestSequential(t *testing.T) {
	m := memo.New(httpGetBody)
	defer m.Close()
	memotest.Sequential(t, m)
}

func TestConcurrent(t *testing.T) {
	m := memo.New(httpGetBody)
	defer m.Close()
	memotest.Concurrent(t, m)
}

```

```go
// memotest.go

package memotest

import (
	"fmt"
	"io/ioutil"
	"log"
	"net/http"
	"sync"
	"testing"
	"time"
)

//!+httpRequestBody
func httpGetBody(url string) (interface{}, error) {
	resp, err := http.Get(url)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()
	return ioutil.ReadAll(resp.Body)
}

//!-httpRequestBody
var HTTPGetBody = httpGetBody

func incomingURLs() <-chan string {
	ch := make(chan string)
	go func() {
		for _, url := range []string{
			"https://golang.org",
			"https://play.golang.org",
			"http://gopl.io",
		} {
			ch <- url
		}
		close(ch)
	}()
	return ch
}

type M interface {
	Get(key string) (interface{}, error)
}

func Sequential(t *testing.T, m M) {
	//!+seq
	for url := range incomingURLs() {
		start := time.Now()
		value, err := m.Get(url)
		if err != nil {
			log.Print(err)
			continue
		}
		fmt.Printf("Sequential(no cache): %s, %s, %d bytes\n",
			url, time.Since(start), len(value.([]byte)))
	}

	for url := range incomingURLs() {
		start := time.Now()
		value, err := m.Get(url)
		if err != nil {
			log.Print(err)
			continue
		}
		fmt.Printf("Sequential(caching): %s, %s, %d bytes\n",
			url, time.Since(start), len(value.([]byte)))
	}
	//!-seq
}

func Concurrent(t *testing.T, m M) {
	//!+conc
	var n sync.WaitGroup
	for url := range incomingURLs() {
		n.Add(1)
		go func(url string) {
			defer n.Done()
			start := time.Now()
			value, err := m.Get(url)
			if err != nil {
				log.Print(err)
				return
			}
			fmt.Printf("Concurrent(no cache) %s, %s, %d bytes\n",
				url, time.Since(start), len(value.([]byte)))
		}(url)
	}
	n.Wait()

	for url := range incomingURLs() {
		n.Add(1)
		go func(url string) {
			defer n.Done()
			start := time.Now()
			value, err := m.Get(url)
			if err != nil {
				log.Print(err)
				return
			}
			fmt.Printf("Concurrent(caching) %s, %s, %d bytes\n",
				url, time.Since(start), len(value.([]byte)))
		}(url)
	}
	n.Wait()
	//!-conc
}
```
```go
// memo.go

package memo

//!+Func

// Func is the type of the function to memoize.
type Func func(key string) (interface{}, error)

// A result is the result of calling a Func.
type result struct {
	value interface{}
	err   error
}

type entry struct {
	res   result
	ready chan struct{} // closed when res is ready
}

// A request is a message requesting that the Func be applied to key.
type request struct {
	key      string
	response chan<- result // the client wants a single result
}

type Memo struct{ requests chan request }

// New returns a memoization of f.  Clients must subsequently call Close.
func New(f Func) *Memo {
	memo := &Memo{requests: make(chan request)}
	go memo.server(f)
	return memo
}

func (memo *Memo) Get(key string) (interface{}, error) {
	response := make(chan result)
	memo.requests <- request{key, response}
	res := <-response
	return res.value, res.err
}

func (memo *Memo) Close() { close(memo.requests) }

//!+monitor

func (memo *Memo) server(f Func) {
	cache := make(map[string]*entry)
	for req := range memo.requests {
		e := cache[req.key]
		if e == nil {
			// This is the first request for this key.
			e = &entry{ready: make(chan struct{})}
			cache[req.key] = e
			go e.call(f, req.key) // call f(key)
		}
		go e.deliver(req.response)
	}
}

func (e *entry) call(f Func, key string) {
	// Evaluate the function.
	e.res.value, e.res.err = f(key)
	// Broadcast the ready condition.
	close(e.ready)
}

func (e *entry) deliver(response chan<- result) {
	// Wait for the ready condition.
	<-e.ready
	// Send the result to the client.
	response <- e.res
}

//!-monitor
```
```
OutPut

$ go test
go test
Sequential(no cache): https://golang.org, 791.115997ms, 57800 bytes
Sequential(no cache): https://play.golang.org, 943.02929ms, 13249 bytes
Sequential(no cache): http://gopl.io, 168.439653ms, 5571 bytes
Sequential(caching): https://golang.org, 7.738µs, 57800 bytes
Sequential(caching): https://play.golang.org, 4.281µs, 13249 bytes
Sequential(caching): http://gopl.io, 3.466µs, 5571 bytes

Concurrent(no cache) http://gopl.io, 164.957744ms, 5571 bytes
Concurrent(no cache) https://golang.org, 467.766094ms, 57800 bytes
Concurrent(no cache) https://play.golang.org, 887.236659ms, 13249 bytes
Concurrent(caching) https://play.golang.org, 6.683µs, 13249 bytes
Concurrent(caching) https://golang.org, 21.606µs, 57800 bytes
Concurrent(caching) http://gopl.io, 10.006µs, 5571 bytes
PASS
ok      gopl.io/ch9/memo5       2.799s
```

해당 코드는 test코드로 동기식 호출 캐시(Sequential), 비 동기식 호출 캐시(Concurrent)로 구성된 코드입니다.
(사실 둘다 별 차이가 없음)
Goroutine-safe된 부분은 `memo.go`의 `server(), Get(()` 부분 입니다.
1. 실행 순서는 `memo.New()` -> `go memo.server()` -> `memo.reqeust` 채널에 수신된게 없으면 일단 대기.
2. `Sequential()` -> `Get()` -> `memo.reqeust` 채널에 `request struct` 송신 -> `Get()의 response()` 수신 대기.
3. `Get()`에서 `memo.request` 채널에 송신을 했음으로 `go memo.server()`에 for문 동작.
4. `e = &entry{ready: make(chan struct{})}` 에서 구조체 포인터를 e로 전달 후 캐시에 적제 -> `call()` 호출
5. `call()` 호출 후 `close(e.ready)`.
6. 그 후 `deliver()`함수가 호출되면 e.res에는 값이 있기 때문에 데이터 꺠짐 없이 무사히 처리 가능.

## 9.8 고루틴과 쓰레드

### 9.8.1 가변 스택
일반적인 쓰레드는 고정 크기의 스택 메모리 블록을 할당받아 사용합니다.(2MB)
이러한 쓰레드 메모리는 고루틴 메모리에 비해서 많이 낭비입니다. 또한 깊은 재귀 함수나 많은 양의 쓰레드(1000개 이상)는 실행이 불가능 합니다.
(쓰레드 같은 경우 운영체제나 라이브러리에서 관리해 주는데 갯수에 재한을 둡니다.)

반면 고루틴은 가변 스택을 사용하고 있습니다. 고루틴당 2KB를 할당 받으며 스택에 크기는 1GB까지 될 수 있다고 합니다.
또한 쓰레드에 비해 고루틴은 가벼운데, 쓰레드는 16개의 범용 레지스터, PC(Program Counter), SP(Stack Pointer), segment레지스터, 16개의 XMM 레지스터,
FP coprocessor state, 16개의 AVX레지스터 등을 save/restore하며 프로세스보단 가볍지만 context를 유발하기 때문에 성능 저하를 무시하지 못합니다.

반면 goroutine은 Program Counter, Stack Pointer, DX 3개만 사용하며 save/restore하기 때문에 비용적인 측면에서도 유리합니다.

고 스택을 어떻게 관리하고 있는지 궁금하시다면 해당 링크를 참조해주세요.
https://stackoverflow.com/questions/67659524/is-gos-stack-split-or-stack-copy

### 9.8.2 고루틴 스케줄링
일반적인 OS 쓰레드는 OS 커널에 의해 스케줄됩니다. 매 밀리초마다 하드웨어 타이머가 프로세서를 인터셉트해 커널 함수 scheduler가 호출됩니다.
이 기능을 사용해 쓰레드간 context switching을 해줍니다.

하지만 Go의 고루틴은 자체 스케줄러가 고루틴을 관리합니다.
Go 스케줄러는 m:n스케줄링 기법으로 커널 스케줄러와 유사하게 동작합니다.
(m:n 스케줄링은 n개의 OS쓰레드에서 m개의 고루틴을 스케줄링 할 수 있습니다. 참고. https://rakyll.org/scheduler/)

### 9.8.3 GOMAXPROCS
Go 스케줄러는 GOMAXPROCS라는 파라미터를 사용해서 동시에 얼마나 많은 OS 쓰레드에서 Go 코드를 수행할지 결정합니다.
보통 GOMAXPROCS값은 CPU 개수로 적기 때문에 4코어 CPU라면 GOMAXPROCS값을 4로 지정합니다.
(그럼 4개의 쓰레드가 고루틴을 관리하게 됩니다.)

```go
package main

import "fmt"

func main() {
	for {
		go fmt.Print(0)
		fmt.Print(1)
	}
}

// GOMAXPROCS=1 (Default)
$ go run main.go 
11111111111101111111001101011110110111110011000000010110010

//GOMAXPROCS=2 (Default)
 GOMAXPROCS=2 go run main.go 
111001110111101001001110100001110011111111110100011000000000000011111111101

GOMAXPROCS=8 go run main.go
11111111010100000110010001111111111111100001000000000011011000
```

### 9.8.4 고루틴에는 식별자가 없다.
대부분의 쓰레드는 일반적인 값인 정수나 포인터로 쉽게 얻을 수 있는 독자적인 식별자가 있습니다.
이는 스레드를 식별자 키로 갖는 전역 맵인 스레드 로컬 스토리지라는 추상화 계층을 만들기 쉽게하기 위한 것이고, 
각 스레드는 이 저장 공간을 통해 다른 스레드와 독립적으로 값을 저장하고 읽을 수 있습니다.

하지만 고루틴에는 개발자가 접근 가능한 식별자에 대한 표현 방법이 없습니다.
이는 쓰레드 로컬 스토리지가 남용되는 경향이 있기 때문에 의도적으로 설계된 것입니다. 
TLS(Thread Local Storage) : https://en.wikipedia.org/wiki/Thread-local_storage

쓰레드의 경우 전역변수에 의존하는 경우가 많은데, 이를 해결하기 위해서 TLS를 사용합니다.
이를 원격 작업(Action at a distance)라고 하는데, 여기서 생기는 버그가 잘못된 시간에 작업을 수행하거나, 해서는 안되는 작업을 수행하여
프로그램에 영향을 끼칠 수 있다고 합니다. 
(참고. https://en.wikipedia.org/wiki/Action_at_a_distance)

Go는 함수의 동작에 영향을 주는 파라미터를 명시하게 하는 단순한 방식의 프로그래밍을 권장합니다.
이렇게 하면 프로그램이 읽기 쉬워질 뿐더러 주어진 함수의 하위 작업을 식별자에 신경 쓰지 않고 여러 고루틴에 자유롭게 할당할 수 있습니다.
또한 채널을 통해 값을 주고 받으므로 안전합니다.
